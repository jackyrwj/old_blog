---
layout: post
title: "LRU算法"
date:   2023-4-11
tags: [算法]
comments: true
author: Jackyrwj
toc: true
---

![](https://raw.githubusercontent.com/jackyrwj/picb/master/20230527002310.png)


> LRU 缓存淘汰算法就是一种常用策略。LRU 的全称是 Least Recently Used，也就是说我们认为最近使用过的数据应该是「有用的」，很久都没用过的数据应该是无用的，内存满了就优先删那些很久没用过的数据。**核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高**

## 一、LRU 算法设计

没有使用双向链表， adjust 函数的时间复杂度达到了O(n)

```java
class LRUCache {
    private int capacity;
    int size;
    private HashMap<Integer, Integer> map = new HashMap<>();
    private ArrayDeque<Integer> KEY = new ArrayDeque<>();

    public LRUCache(int capacity) {
        this.capacity = capacity;
        this.size = 0;
    }
    
    public int get(int key) {
        if(map.containsKey(key))
        {
            adjust(key);
            return map.get(key);
        }
        return -1;
    }

    public void adjust(int key)
    {
        KEY.remove(key);
        KEY.offer(key);
    }
    
    public void put(int key, int value) {
        if(map.containsKey(key))
        {
            adjust(key);
        }
        else
        {
            size++;
            KEY.offer(key);
        }
        map.put(key, value);
        if(size > capacity)
        {
            map.remove(KEY.poll());
            size--;
        }
    }
}

```

LRU 更好的设计是使用双向链表+HashMap

```java
class LRUCache {
    private DoubleList cache;
    private HashMap<Integer, Node> map;
    private int size;
    private int capacity;

    public LRUCache(int capacity) {
        cache = new DoubleList();
        map = new HashMap<Integer, Node>();
        size = 0;
        this.capacity = capacity;
    }
    
    public int get(int key) {
        if (!map.containsKey(key))
            return -1;
        Node node = map.get(key);
        cache.remove(node);
        cache.add(node);
        return node.val;
    }

    public void adjust(Node node) {
        cache.remove(node);
        cache.add(node);
    }
    
    public void put(int key, int value) {
        Node node;
        if (map.containsKey(key)) {
            node = map.get(key);
            cache.remove(node);
        } else {
            if (size == capacity) {
                node = cache.getHead();
                map.remove(node.key);
                cache.remove(node);
                size--;
            }
            size++;
        }
        node = new Node(key, value);
        cache.add(node);
        map.put(key, node);
    }
}

class Node {
    int key, val;
    Node prev;
    Node next;
    Node(int key, int val) {
        this.key = key;
        this.val = val;
    }
    Node() {}
}

class DoubleList {
    private Node dummyHead = new Node(0, 0), tail = dummyHead;
    
    public void add(Node x) {
        tail.next = x;
        x.prev = tail;
        tail = x;
    }

    public void remove(Node x) {
        x.prev.next = x.next;
        if (x.next != null) {
            x.next.prev = x.prev;
        } else {
            tail = x.prev;
        }
        x.prev = null;
        x.next = null;
    }

    public Node getHead() {
        return dummyHead.next;
    }
}
```
